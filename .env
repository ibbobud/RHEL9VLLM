# Edit the .env file to change the following variables before running the docker compose command.
# (default values are shown below)
# See the vllm documentation for more arguments https://docs.vllm.ai/en/latest/models/engine_args.html

# Name of the huggingface model to use
MODEL='TheBloke/NeuralHermes-2.5-Mistral-7B-AWQ'

# --quantization (-q) {awq,squeezellm,None} (Method used to quantize the weights.)
QUANTIZATION='awq'

# --dtype {auto,half,float16,bfloat16,float,float32} (Data type for model weights and activations.)
DTYPE='auto'

# --max-model-len <length> (Model context length. If unspecified, will be automatically derived from the model config.)
MAX_MODEL_LEN='4096'

# API-SERVER type {openai,''}
API_SERVER='openai'